{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow 모델 저장 복구 튜토리얼"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 어떻게 모델은 보이는가\n",
    "- 어떻게 모델은 저장 되는가\n",
    "- prediction과 transfer learning을 위한 restoe 방법\n",
    "- pre-trained model을 불러오는 방법 fine-tuning을 위해서"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'./my_test_model-1000'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Prepare to feed input, i.e. feed_dict and placeholders\n",
    "w1 = tf.placeholder(tf.float32, name=\"w1\")\n",
    "w2 = tf.placeholder(tf.float32, name=\"w2\")\n",
    "b1 = tf.Variable(2.0,dtype=tf.float32, name=\"bias\")\n",
    "feed_dict = {'w1': 4.0, 'w2': 8.0}\n",
    "\n",
    "# Define a test operation that we will restore\n",
    "w3 = w1 + w2\n",
    "w4 = tf.multiply(w3, b1, name=\"op_to_restore\")\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# Create a saver object which will save all the variables\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# Run the operation by feeding input\n",
    "result = sess.run(w4, {w1:feed_dict['w1'], w2:feed_dict['w2']})\n",
    "print(result)\n",
    "# Prints 24 which is sum of (w1+w2)*b1\n",
    "\n",
    "# Now, save the graph\n",
    "saver.save(sess, './my_test_model', global_step=1000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "복구를 위해서는\n",
    "- graph \n",
    "- variable\n",
    "\n",
    "모두를 restore 해야 한다.  \n",
    "이것을 통해서 새로운 training data를 `feed`할 수 있다.  \n",
    "`graph.get_tensor_by_name()` method를 통해서 saved operation과 placeholder variables의 reference를 얻을 수 있다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "만약 같은 네트워크에 다른 data를 넣어서 처리하고 싶다면 간단하게 feed_dict을 네트워크에 넣는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_test_model-1000\n",
      "60.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "sess=tf.Session()    \n",
    "#First let's load meta graph and restore weights\n",
    "saver = tf.train.import_meta_graph('my_test_model-1000.meta')\n",
    "saver.restore(sess,tf.train.latest_checkpoint('./'))\n",
    "\n",
    "\n",
    "# Now, let's access and create placeholders variables and\n",
    "# create feed-dict to feed new data\n",
    "\n",
    "graph = tf.get_default_graph()\n",
    "w1 = graph.get_tensor_by_name(\"w1:0\")\n",
    "w2 = graph.get_tensor_by_name(\"w2:0\")\n",
    "feed_dict ={w1:13.0,w2:17.0}\n",
    "\n",
    "#Now, access the op that you want to run. \n",
    "op_to_restore = graph.get_tensor_by_name(\"op_to_restore:0\")\n",
    "\n",
    "print (sess.run(op_to_restore,feed_dict))\n",
    "#This will print 60 which is calculated \n",
    "#using new values of w1 and w2 and saved value of b1. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "만약 operation과 layer를 좀 더 추가하고 싶다면 아래와 같이 수행 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_test_model-1000\n",
      "120.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "sess=tf.Session()    \n",
    "#First let's load meta graph and restore weights\n",
    "saver = tf.train.import_meta_graph('my_test_model-1000.meta')\n",
    "saver.restore(sess,tf.train.latest_checkpoint('./'))\n",
    "\n",
    "\n",
    "# Now, let's access and create placeholders variables and\n",
    "# create feed-dict to feed new data\n",
    "\n",
    "graph = tf.get_default_graph()\n",
    "w1 = graph.get_tensor_by_name(\"w1:0\")\n",
    "w2 = graph.get_tensor_by_name(\"w2:0\")\n",
    "feed_dict ={w1:13.0,w2:17.0}\n",
    "\n",
    "#Now, access the op that you want to run. \n",
    "op_to_restore = graph.get_tensor_by_name(\"op_to_restore:0\")\n",
    "\n",
    "#Add more to the current graph\n",
    "add_on_op = tf.multiply(op_to_restore,2)\n",
    "\n",
    "print (sess.run(add_on_op,feed_dict))\n",
    "#This will print 120."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "만약 fine-tuning을 위해서 일부분만 저장하고 복구하고 싶다면?  \n",
    "`graph.get_tensor_by_name()` method를 이용해서 적절한 operation만 접근할 수 있다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
